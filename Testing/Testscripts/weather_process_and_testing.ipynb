{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install required modules and libraries\n",
    "#! pip install pyarrow\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import os\n",
    "\n",
    "#iterate over csv files into pandas selecting only the required columns\n",
    "#create a compressed parquet dataset by year>month>region for a smaller footprint and faster querying\n",
    "\n",
    "def weatherResults():\n",
    "    for file in os.listdir():\n",
    "        if file.endswith(\".csv\"):\n",
    "            file1 = file\n",
    "            df = pd.read_csv(os.path.abspath(file1))\n",
    "\n",
    "\n",
    "            df = df[['ForecastSiteCode','ObservationTime','ObservationDate','ScreenTemperature','SiteName','Region']]\n",
    "            df = df.sort_values(by=['ForecastSiteCode','ObservationDate','ObservationTime'])\n",
    "            df = df.reset_index(drop=True)\n",
    "            df['ObsYear'] = pd.DatetimeIndex(df['ObservationDate']).year\n",
    "            df['ObsMonth'] = pd.DatetimeIndex(df['ObservationDate']).month\n",
    "            df['ObsDay'] = pd.DatetimeIndex(df['ObservationDate']).day\n",
    "\n",
    "            table = pa.Table.from_pandas(df)\n",
    "\n",
    "            #create files for testing \n",
    "\n",
    "            #file1 = file1.replace(\".csv\",\".\")\n",
    "            #file2 = file1 + 'parquet.snappy'\n",
    "            #pq.write_table(table, file2,compression='snappy')\n",
    "\n",
    "            return pq.write_to_dataset(table,root_path='weather_results',partition_cols=['ObsYear','ObsMonth','Region'])\n",
    "        \n",
    "\n",
    "def maxTemp():\n",
    "    #read parquet dataset into pandas dataframe and filter for max temp - print back required columns\n",
    "\n",
    "    weather_data = pq.ParquetDataset('weather_results/')\n",
    "    table = weather_data.read()\n",
    "    weather_table_df = table.to_pandas()\n",
    "\n",
    "    weather_result = weather_table_df.loc[weather_table_df['ScreenTemperature'].idxmax()]\n",
    "\n",
    "    temp = weather_result['ScreenTemperature']\n",
    "    date = weather_result['ObservationDate'][:9]\n",
    "    region = weather_result['Region']\n",
    "\n",
    "    print(\"Which date was the hottest day? \",date)\n",
    "    print(\"\") \n",
    "    print(\"What was the temperature on that day? \",temp)\n",
    "    print(\"\")        \n",
    "    print(\"In which region was the hottest day? \",region) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.6 15.8\n"
     ]
    }
   ],
   "source": [
    "#Testing\n",
    "\n",
    "\n",
    "#open files in excel note down row details for maximum temps\n",
    "df1 = pd.read_csv(os.path.abspath('weather.20160201.csv'))\n",
    "df2 = pd.read_csv(os.path.abspath('weather.20160301.csv'))\n",
    "\n",
    "print(df1['ScreenTemperature'].max(),df2['ScreenTemperature'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ForecastSiteCode: int64\n",
       "  -- field metadata --\n",
       "  PARQUET:field_id: '1'\n",
       "ObservationTime: int64\n",
       "  -- field metadata --\n",
       "  PARQUET:field_id: '2'\n",
       "ObservationDate: string\n",
       "  -- field metadata --\n",
       "  PARQUET:field_id: '3'\n",
       "ScreenTemperature: double\n",
       "  -- field metadata --\n",
       "  PARQUET:field_id: '4'\n",
       "SiteName: string\n",
       "  -- field metadata --\n",
       "  PARQUET:field_id: '5'\n",
       "ObsDay: int64\n",
       "  -- field metadata --\n",
       "  PARQUET:field_id: '6'\n",
       "ObsYear: dictionary<values=int64, indices=int32, ordered=0>\n",
       "ObsMonth: dictionary<values=int64, indices=int32, ordered=0>\n",
       "Region: dictionary<values=string, indices=int32, ordered=0>\n",
       "-- schema metadata --\n",
       "pandas: '{\"index_columns\": [], \"column_indexes\": [], \"columns\": [{\"name\":' + 822"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check schema of dataset as table\n",
    "table.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check parquet file metadata and schema\n",
    "\n",
    "wather_20160301_file = pq.ParquetFile(os.path.abspath('weather.20160301.parquet.snappy'))\n",
    "wather_20160201_file = pq.ParquetFile(os.path.abspath('weather.20160201.parquet.snappy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow._parquet.FileMetaData object at 0x00000196BB3F7D68>\n",
       "  created_by: parquet-cpp version 1.5.1-SNAPSHOT\n",
       "  num_columns: 9\n",
       "  num_rows: 101442\n",
       "  num_row_groups: 1\n",
       "  format_version: 1.0\n",
       "  serialized_size: 5435"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wather_20160301_file.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow._parquet.FileMetaData object at 0x00000196BB3C5688>\n",
       "  created_by: parquet-cpp version 1.5.1-SNAPSHOT\n",
       "  num_columns: 9\n",
       "  num_rows: 93255\n",
       "  num_row_groups: 1\n",
       "  format_version: 1.0\n",
       "  serialized_size: 5435"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wather_20160201_file.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow._parquet.ParquetSchema object at 0x00000196B85964A8>\n",
       "required group field_id=0 schema {\n",
       "  optional int64 field_id=1 ForecastSiteCode;\n",
       "  optional int64 field_id=2 ObservationTime;\n",
       "  optional binary field_id=3 ObservationDate (String);\n",
       "  optional double field_id=4 ScreenTemperature;\n",
       "  optional binary field_id=5 SiteName (String);\n",
       "  optional binary field_id=6 Region (String);\n",
       "  optional int64 field_id=7 ObsYear;\n",
       "  optional int64 field_id=8 ObsMonth;\n",
       "  optional int64 field_id=9 ObsDay;\n",
       "}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wather_20160301_file.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow._parquet.ParquetSchema object at 0x00000196B8559860>\n",
       "required group field_id=0 schema {\n",
       "  optional int64 field_id=1 ForecastSiteCode;\n",
       "  optional int64 field_id=2 ObservationTime;\n",
       "  optional binary field_id=3 ObservationDate (String);\n",
       "  optional double field_id=4 ScreenTemperature;\n",
       "  optional binary field_id=5 SiteName (String);\n",
       "  optional binary field_id=6 Region (String);\n",
       "  optional int64 field_id=7 ObsYear;\n",
       "  optional int64 field_id=8 ObsMonth;\n",
       "  optional int64 field_id=9 ObsDay;\n",
       "}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wather_20160201_file.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather(directorypath):\n",
    "    return os.chdir(directorypath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pqdataSet():\n",
    "    for file in os.listdir():\n",
    "        if file.endswith(\".csv\"):\n",
    "            file1 = file\n",
    "            df = pd.read_csv(os.path.abspath(file1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pqdataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "directorypath = \"\\\\Users\\walea\\Downloads\\Data_Engineer_Test_Green_Flag\"\n",
    "#directorypath = directorypath.replace(\"\\\\\",\"//\")\n",
    "#directorypath "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 0-1: truncated \\UXXXXXXXX escape (<ipython-input-38-c22d8caf8d74>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-38-c22d8caf8d74>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    weather('\\Users\\walea\\Downloads\\Data_Engineer_Test_Green_Flag')\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 0-1: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "weather('\\Users\\walea\\Downloads\\Data_Engineer_Test_Green_Flag')\n",
    "\n",
    "raw_s = r'{}'.format('\\Users\\walea\\Downloads\\Data_Engineer_Test_Green_Flag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\walea\\\\Downloads\\\\Data_Engineer_Test_Green_Flag'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (<ipython-input-53-096485d4ef89>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-53-096485d4ef89>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    s = \"C:\\Users\\walea\\Downloads\\Data_Engineer_Test_Green_Flag\"\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob, os\n",
    "\n",
    "\n",
    "class Weather:\n",
    "\n",
    "    def __init__(self, source_path, destination_path):\n",
    "        self.source_path = source_path\n",
    "        self.destination_path = destination_path\n",
    "        self.weather_df = None\n",
    "        self.combined_weather_df = None\n",
    "        self.generate_weather_df()\n",
    "\n",
    "    def generate_weather_df(self):\n",
    "        self.read_weather_csv_data_files()\n",
    "\n",
    "    def read_weather_csv_data_files(self):\n",
    "        '''\n",
    "        Read required data columns from csv files source location and concatenate them\n",
    "        in to a panda dataframe.\n",
    "        '''\n",
    "        files = glob.glob(os.path.join(self.source_path, \"*.csv\"))\n",
    "        weather_data_csv = [pd.read_csv(f, usecols=[\"ObservationDate\", \"ScreenTemperature\", \"Region\"]\n",
    "                                        , converters={'ScreenTemperature': lambda x: (x.replace('-99', '0')),\n",
    "                                                      'ObservationDate': lambda x: (pd.Timestamp(x).date())}\n",
    "                                        ) for f in files]\n",
    "        weather_data_csv_files = pd.concat(weather_data_csv, ignore_index=True)\n",
    "        weather_data_csv_files['ScreenTemperature'] = pd.to_numeric(weather_data_csv_files['ScreenTemperature'])\n",
    "        weather_data_csv_files.style.format({'ScreenTemperature': '{:,.1f}'.format})\n",
    "        self.save_df_to_parquet_file(weather_data_csv_files)\n",
    "        return weather_data_csv_files\n",
    "\n",
    "    def save_df_to_parquet_file(self, weather_data_csv):\n",
    "        '''\n",
    "        Save panda dataframe to parquet file to output path\n",
    "        :param weather_data_csv.\n",
    "        '''\n",
    "        output_path = os.path.join(self.destination_path, 'weather_data.parquet')\n",
    "        weather_data_csv.to_parquet(output_path)\n",
    "        self.load_parquet_file_to_df()\n",
    "\n",
    "    def load_parquet_file_to_df(self):\n",
    "        '''\n",
    "        Load data to panda dataframe from parquet file\n",
    "        '''\n",
    "        self.weather_df = pd.read_parquet(self.destination_path)\n",
    "\n",
    "    def hottest_day_date(self):\n",
    "        '''\n",
    "        Calculate and hottest day date\n",
    "        :return: series: pandas series returning hottest day date\n",
    "        '''\n",
    "        grouped_by_date = self.weather_df.groupby(['ObservationDate'], as_index=False)\n",
    "        average_temperature_for_dates = grouped_by_date.mean()\n",
    "        hottest_day_date = average_temperature_for_dates[['ObservationDate']].loc[\n",
    "            average_temperature_for_dates['ScreenTemperature'].idxmax()]\n",
    "        return hottest_day_date\n",
    "\n",
    "    def hottest_day_average_temperature(self):\n",
    "        '''\n",
    "        Calculate and hottest day temperature\n",
    "        :return: series: pandas series returning hottest day temperature\n",
    "        '''\n",
    "        grouped_by_date = self.weather_df.groupby(['ObservationDate'], as_index=False)\n",
    "        average_temperature_for_dates = grouped_by_date.mean()\n",
    "        hottest_day_temperature = average_temperature_for_dates[['ScreenTemperature']].loc[\n",
    "            average_temperature_for_dates['ScreenTemperature'].idxmax()]\n",
    "        return hottest_day_temperature\n",
    "\n",
    "    def hottest_day_average_temperature_by_region(self):\n",
    "        '''\n",
    "        Calculate and hottest day temperature by region\n",
    "        :return: series: pandas series returning hottest day by region\n",
    "        '''\n",
    "        grouped_by_date_region = self.weather_df.groupby(['ObservationDate', 'Region'], as_index=False)\n",
    "        average_temperature_for_dates_region = grouped_by_date_region.mean()\n",
    "        hottest_day_temperature_region = average_temperature_for_dates_region[['ObservationDate', 'Region']].loc[\n",
    "            average_temperature_for_dates_region['ScreenTemperature'].idxmax()]\n",
    "        return hottest_day_temperature_region\n",
    "\n",
    "    def get_results(self):\n",
    "        '''\n",
    "        Concatinate all series data to a Pandas dataframe\n",
    "        :return: dataframe: pandas dataframe returning hottest day date\n",
    "                            hottest day temperature and hottest day by region\n",
    "        '''\n",
    "        pd.set_option('display.max_columns', 3)\n",
    "        self.combined_weather_df = pd.concat([self.hottest_day_date(), self.hottest_day_average_temperature(),\n",
    "                                              self.hottest_day_average_temperature_by_region()], sort=True, axis=1,\n",
    "                                             ignore_index=True)\n",
    "\n",
    "        self.combined_weather_df.rename(columns={self.combined_weather_df.columns[0]: \"hottest_day_date\",\n",
    "                                                 self.combined_weather_df.columns[1]: \"hottest_day_temperature\",\n",
    "                                                 self.combined_weather_df.columns[2]: \"hottest_day_by_region\"}\n",
    "                                        , inplace=True)\n",
    "        return self.combined_weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weather = Weather('/Users/walea/Desktop/New1','/Users/walea/Desktop/other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hottest_day_date</th>\n",
       "      <th>hottest_day_temperature</th>\n",
       "      <th>hottest_day_by_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ObservationDate</th>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>East of England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScreenTemperature</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.153981</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  hottest_day_date  hottest_day_temperature  \\\n",
       "ObservationDate         2016-02-01                      NaN   \n",
       "Region                         NaN                      NaN   \n",
       "ScreenTemperature              NaN                 9.153981   \n",
       "\n",
       "                  hottest_day_by_region  \n",
       "ObservationDate              2016-02-21  \n",
       "Region                  East of England  \n",
       "ScreenTemperature                   NaN  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_weather.get_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
