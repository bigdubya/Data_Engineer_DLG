{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which date was the hottest day?  2016-03-1\n",
      "\n",
      "What was the temperature on that day?  15.8\n",
      "\n",
      "In which region was the hottest day?  Highland & Eilean Siar\n"
     ]
    }
   ],
   "source": [
    "#install required modules and libraries\n",
    "#! pip install pyarrow\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import os\n",
    "\n",
    "#set directory to folder containing underlying .csv's\n",
    "\n",
    "os.chdir(\"/Users/walea/Downloads/Data_Engineer_Test_Green_Flag\")\n",
    "\n",
    "#iterate over csv files into pandas selecting only the required columns\n",
    "#create a compressed parquet dataset by year>month>region for a smaller footprint and faster querying\n",
    "\n",
    "for file in os.listdir():\n",
    "    if file.endswith(\".csv\"):\n",
    "        file1 = file\n",
    "        df = pd.read_csv(os.path.abspath(file1))\n",
    "\n",
    "\n",
    "        df = df[['ForecastSiteCode','ObservationTime','ObservationDate','ScreenTemperature','SiteName','Region']]\n",
    "        df = df.sort_values(by=['ForecastSiteCode','ObservationDate','ObservationTime'])\n",
    "        df = df.reset_index(drop=True)\n",
    "        df['ObsYear'] = pd.DatetimeIndex(df['ObservationDate']).year\n",
    "        df['ObsMonth'] = pd.DatetimeIndex(df['ObservationDate']).month\n",
    "        df['ObsDay'] = pd.DatetimeIndex(df['ObservationDate']).day\n",
    "        \n",
    "        table = pa.Table.from_pandas(df)\n",
    "        \n",
    "        #create files for testing \n",
    "        \n",
    "        file1 = file1.replace(\".csv\",\".\")\n",
    "        file2 = file1 + 'parquet.snappy'\n",
    "        pq.write_table(table, file2,compression='snappy')\n",
    "        \n",
    "        pq.write_to_dataset(table,root_path='weather_results',partition_cols=['ObsYear','ObsMonth','Region'])\n",
    "        \n",
    "\n",
    "#read parquet dataset into pandas dataframe and filter for max temp - print back required columns\n",
    "\n",
    "weather_data = pq.ParquetDataset('weather_results/')\n",
    "table = weather_data.read()\n",
    "weather_table_df = table.to_pandas()\n",
    "\n",
    "weather_result = weather_table_df.loc[weather_table_df['ScreenTemperature'].idxmax()]\n",
    "\n",
    "temp = weather_result['ScreenTemperature']\n",
    "date = weather_result['ObservationDate'][:9]\n",
    "region = weather_result['Region']\n",
    "\n",
    "print(\"Which date was the hottest day? \",date)\n",
    "print(\"\") \n",
    "print(\"What was the temperature on that day? \",temp)\n",
    "print(\"\")        \n",
    "print(\"In which region was the hottest day? \",region) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.6 15.8\n"
     ]
    }
   ],
   "source": [
    "#Testing\n",
    "\n",
    "\n",
    "#open files in excel note down row details for maximum temps\n",
    "df1 = pd.read_csv(os.path.abspath('weather.20160201.csv'))\n",
    "df2 = pd.read_csv(os.path.abspath('weather.20160301.csv'))\n",
    "\n",
    "print(df1['ScreenTemperature'].max(),df2['ScreenTemperature'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ForecastSiteCode: int64\n",
       "  -- field metadata --\n",
       "  PARQUET:field_id: '1'\n",
       "ObservationTime: int64\n",
       "  -- field metadata --\n",
       "  PARQUET:field_id: '2'\n",
       "ObservationDate: string\n",
       "  -- field metadata --\n",
       "  PARQUET:field_id: '3'\n",
       "ScreenTemperature: double\n",
       "  -- field metadata --\n",
       "  PARQUET:field_id: '4'\n",
       "SiteName: string\n",
       "  -- field metadata --\n",
       "  PARQUET:field_id: '5'\n",
       "ObsDay: int64\n",
       "  -- field metadata --\n",
       "  PARQUET:field_id: '6'\n",
       "ObsYear: dictionary<values=int64, indices=int32, ordered=0>\n",
       "ObsMonth: dictionary<values=int64, indices=int32, ordered=0>\n",
       "Region: dictionary<values=string, indices=int32, ordered=0>\n",
       "-- schema metadata --\n",
       "pandas: '{\"index_columns\": [], \"column_indexes\": [], \"columns\": [{\"name\":' + 822"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check schema of dataset as table\n",
    "table.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check parquet file metadata and schema\n",
    "\n",
    "wather_20160301_file = pq.ParquetFile(os.path.abspath('weather.20160301.parquet.snappy'))\n",
    "wather_20160201_file = pq.ParquetFile(os.path.abspath('weather.20160201.parquet.snappy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow._parquet.FileMetaData object at 0x00000196BB3F7D68>\n",
       "  created_by: parquet-cpp version 1.5.1-SNAPSHOT\n",
       "  num_columns: 9\n",
       "  num_rows: 101442\n",
       "  num_row_groups: 1\n",
       "  format_version: 1.0\n",
       "  serialized_size: 5435"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wather_20160301_file.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow._parquet.FileMetaData object at 0x00000196BB3C5688>\n",
       "  created_by: parquet-cpp version 1.5.1-SNAPSHOT\n",
       "  num_columns: 9\n",
       "  num_rows: 93255\n",
       "  num_row_groups: 1\n",
       "  format_version: 1.0\n",
       "  serialized_size: 5435"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wather_20160201_file.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow._parquet.ParquetSchema object at 0x00000196B85964A8>\n",
       "required group field_id=0 schema {\n",
       "  optional int64 field_id=1 ForecastSiteCode;\n",
       "  optional int64 field_id=2 ObservationTime;\n",
       "  optional binary field_id=3 ObservationDate (String);\n",
       "  optional double field_id=4 ScreenTemperature;\n",
       "  optional binary field_id=5 SiteName (String);\n",
       "  optional binary field_id=6 Region (String);\n",
       "  optional int64 field_id=7 ObsYear;\n",
       "  optional int64 field_id=8 ObsMonth;\n",
       "  optional int64 field_id=9 ObsDay;\n",
       "}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wather_20160301_file.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow._parquet.ParquetSchema object at 0x00000196B8559860>\n",
       "required group field_id=0 schema {\n",
       "  optional int64 field_id=1 ForecastSiteCode;\n",
       "  optional int64 field_id=2 ObservationTime;\n",
       "  optional binary field_id=3 ObservationDate (String);\n",
       "  optional double field_id=4 ScreenTemperature;\n",
       "  optional binary field_id=5 SiteName (String);\n",
       "  optional binary field_id=6 Region (String);\n",
       "  optional int64 field_id=7 ObsYear;\n",
       "  optional int64 field_id=8 ObsMonth;\n",
       "  optional int64 field_id=9 ObsDay;\n",
       "}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wather_20160201_file.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
